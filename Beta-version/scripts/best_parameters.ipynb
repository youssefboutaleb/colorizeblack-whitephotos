{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egVNuK3XDPzn"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/youssefboutaleb/colorizeblack-whitephotos\n",
        "import os\n",
        "os.listdir(\"/content/colorizeblack-whitephotos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libs\n",
        "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "TV-UOIIsDSim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get images\n",
        "\n",
        "import random\n",
        "X = []\n",
        "#choose a random folder \n",
        "data=\"Train\"+str(random.randint(0, 7))\n",
        "print(data)\n",
        "for filename in os.listdir('/content/colorizeblack-whitephotos/Beta-version/Train/'+data):\n",
        "    X.append(img_to_array(load_img('/content/colorizeblack-whitephotos/Beta-version/Train/'+data+\"/\"+filename)))\n",
        "X = np.array(X, dtype=float)\n",
        "# Set up training and test data\n",
        "split = int(0.95*len(X))\n",
        "Xtrain = X[:split]\n",
        "Xtrain = 1.0/255*Xtrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcDOcb9dDW-i",
        "outputId": "cf07901b-ff8b-482e-8fee-edc9d3696d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Design the neural network\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))"
      ],
      "metadata": {
        "id": "BJoMTTxTDcsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finish model\n",
        "model.compile(optimizer='rmsprop', loss='mse')\n"
      ],
      "metadata": {
        "id": "Z6y73C6ODfw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transformer\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "# Generate training data\n",
        "batch_size = 50\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"
      ],
      "metadata": {
        "id": "09zvWf_iDj-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = float('inf') \n",
        "best_params = None\n",
        "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
        "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
        "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
        "Ytest = Ytest / 128\n",
        "#find Best parameters\n",
        "for batch_size in [32, 64, 128]:\n",
        "    for epochs in [10, 15, 20]:\n",
        "        for steps_per_epoch in [500, 700, 900]:\n",
        "            print(f'Trying batch_size={batch_size}, epochs={epochs}, steps_per_epoch={steps_per_epoch}')\n",
        "            \n",
        "            \n",
        "            model.fit(image_a_b_gen(batch_size), \n",
        "                                steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
        "                                \n",
        "            val_loss = model.evaluate(Xtest, Ytest, batch_size=batch_size)\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss \n",
        "                best_params = {'batch_size': batch_size, \n",
        "                              'epochs': epochs,\n",
        "                              'steps_per_epoch': steps_per_epoch}\n",
        "\n",
        "print(f'Best parameters: {best_params} with validation loss={best_loss}')"
      ],
      "metadata": {
        "id": "M_Od-OZnT_aV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}